{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d71ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "0.11.2\n",
      "1.21.4\n",
      "1.3.3\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import sklearn\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(tensorflow.__version__)\n",
    "# print(matplotlib.__version__)\n",
    "print(sns.__version__)\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751aacd",
   "metadata": {},
   "source": [
    "### 데이터 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484a446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "훈련 샘플 레이블의 수: 8982\n",
      "테스트 샘플 레이블의 수: 2246\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "index_to_word:  it\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "x_train 길이: 8982\n",
      "x_test 길이: 2246\n"
     ]
    }
   ],
   "source": [
    "#로이터 뉴스 데이터를 훈련 데이터와 테스트 데이터로 나누어 변수에 각각 저장합니다.\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "\n",
    "#데이터가 어떤 구성을 가지고 있는지 출력\n",
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "\n",
    "print('훈련 샘플 레이블의 수: {}'.format(len(y_train)))\n",
    "print('테스트 샘플 레이블의 수: {}'.format(len(y_test)))\n",
    "\n",
    "#뉴스 데이터를 다루기로 했는데, 실제 출력해보면 텍스트가 아니라 숫자 시퀀스가 출력\n",
    "#각 단어가 빈도수가 높은 순서대로 낮은 정수가 맵핑\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "#클래스 확인\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "#로이터 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 dictionary를 제공합니다. 이를 word_index로 저장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index['it']\n",
    "\n",
    "\n",
    "#word_index보다는 정수로부터 단어를 얻을 수 있는index_word가 필요\n",
    "#word_index의 결과로 나오는 숫자에 ***3을 더해주어야*** 단어가 실제로 맵핑된 인덱스 값이 나옵\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "#13+3\n",
    "print('index_to_word: ', index_to_word[16])\n",
    "\n",
    "#0번, 1번, 2번 인덱스에는 각각 , , 라는 특별한 토큰이 맵핑되어 있다고 했죠? 그래서 만들어진 index_to_word에 이 토큰들도 추가해주어야 진짜 index_to_word가 완성\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "#전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print('x_train 길이:', len( x_train))\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print('x_test 길이:', len(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d616",
   "metadata": {},
   "source": [
    "### 벡터화 하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd81cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_dtm.shape: (8982, 9670)\n",
      "tfidfv.shape: (8982, 9670)\n",
      "tfidfv_test.shape: (2246, 9670)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#학습 데이터에 대한DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print('x_train_dtm.shape:',x_train_dtm.shape)\n",
    "\n",
    "#이상한 점은 앞에서 데이터를 로드할 때, num_words=10,000이라는 값을 사용했음에도 DTM 열의 개수는 이보다 현저하게 적은 9,670개밖에 되지 않습니다. \n",
    "#그 이유는 DTM이 자체적인 규칙에 따라서 불필요하다고 판단하는 토큰들을 제거하기 때문\n",
    "\n",
    "#TF-IDF Matrix는 사이킷런의 TfidfTransformer()를 통해서 생성할 수 있습니다. \n",
    "#TF-IDF Matrix는 추가적인 전처리를 하지 않는 이상, DTM과 동일한 크기를 가짐\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print('tfidfv.shape:',tfidfv.shape)\n",
    "\n",
    "#테스트 데이터를 DTM으로 변환\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "print('tfidfv_test.shape:',tfidfv_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d92d92",
   "metadata": {},
   "source": [
    "### 다양한 모델들\n",
    "\n",
    "**Complement Naive Bayes Classifier(CNB)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce97e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f365b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff90164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB의 정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"ComplementNB의 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec4e82",
   "metadata": {},
   "source": [
    "**로지스틱 회귀(Logistic Regression)**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e468ca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, max_iter=3000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dfef37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression의 정확도: 0.8107747105966162\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"LogisticRegression의 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa2fe20",
   "metadata": {},
   "source": [
    "**랜덤 포레스트(Random Forest)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c11854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dfeeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier의 정확도: 0.674087266251113\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"RandomForestClassifier의 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4fadb",
   "metadata": {},
   "source": [
    "**그래디언트 부스팅 트리(GradientBoostingClassifier)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69e7454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "769934c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier의 정확도: 0.7662511130899377\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"GradientBoostingClassifier의 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8089924",
   "metadata": {},
   "source": [
    "**보팅(Voting)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161842eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=0)),\n",
       "                             ('cnb', ComplementNB()),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(random_state=0))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(penalty='l2', random_state=0)\n",
    "\n",
    "# Complement Naive Bayes Classifier\n",
    "cnb_clf = ComplementNB()\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_clf),\n",
    "        ('cnb', cnb_clf),\n",
    "        ('gb', gb_clf)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a353c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_classifier의 정확도: 0.7991985752448798\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"voting_classifier의 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f70771",
   "metadata": {},
   "source": [
    "## 테스트 결과\n",
    "\n",
    "**테스트 케이스별 정확도**\n",
    "\n",
    "---\n",
    "1. num_word = 10000\n",
    "   * ComplementNB의 정확도: 0.7707034728406055\n",
    "   * LogisticRegression의 정확도: 0.8085485307212823\n",
    "   * RandomForestClassifier의 정확도: 0.674087266251113\n",
    "   * GradientBoostingClassifier의 정확도: 0.7671415850400712\n",
    "   * voting_classifier의 정확도: 0.8000890471950134(hard), 0.7898486197684773(soft)\n",
    "   * \n",
    "   --> RandomForest(n_estimators=10(5-->10))\n",
    "\n",
    "      RandomForestClassifier의 정확도: 0.7123775601068566\n",
    "\n",
    "      RandomForest(n_estimators=10(5-->20))\n",
    "\n",
    "      RandomForestClassifier의 정확도: 0.7368655387355298\n",
    " \n",
    "2. num_word = 5000\n",
    "   * ComplementNB의 정확도: 0.7707034728406055\n",
    "   * LogisticRegression의 정확도: 0.8063223508459484\n",
    "   * RandomForestClassifier의 정확도: 0.6999109528049866\n",
    "   * GradientBoostingClassifier의 정확도: 0.7658058771148709\n",
    "   * voting_classifier의 정확도: 0.7991985752448798\n",
    "   * \n",
    "   --> RandomForest(n_estimators=10(5-->10))\n",
    "   \n",
    "          RandomForestClassifier의 정확도: 0.7270703472840605\n",
    "   \n",
    "       RandomForest(n_estimators=10(5-->20))\n",
    "   \n",
    "        RandomForestClassifier의 정확도: 0.7497773820124666"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3caf4c0",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "lecture 기준 파라미터로 각 모델에 따른 테스트에서는 RadomForest가 가장 낮은 수치를 기록 하였습니다. \n",
    "\n",
    "RandForest 모델의 결과 중 특이 사항은\n",
    "\n",
    "  * n_estimators(5-->10-->20) 수치를 증가 시켜면 정확도는 비례하여 증가한다.\n",
    "  \n",
    "  * num_words이 수치를 감소(10000-->5000) 시키면 정확도는 반비례하여 증가한다.\n",
    "\n",
    "Voting을 'soft'로 변환하면 더 hard보다 더 낮은 정확도를 보였습니다.\n",
    "\n",
    "다중 분류에서 트리 모델인 RandomForest 가 정확도가 모델 중 가장 낮은 수치를 보였는데,\n",
    "\n",
    "n_estimators 수치를 증가 시키면 정확도는 비례 하여 증가 하였습니다.\n",
    "\n",
    "몇 개 정도 설정 하면 RandomForest  정확도에 유사 하게 접근 할 수 있는지 테스트 해 보는 것도 좋을 것 같습니다.\n",
    "\n",
    "Voting이 정확도가 가장 높지 않을까 예측 했는데, LogisticRegression을 뛰어 넘지 않아,\n",
    "\n",
    "문제에 맞는 모델을 사용하는 것이 중요 하다고 느꼈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88a573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
