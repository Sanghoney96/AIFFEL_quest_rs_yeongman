{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b9ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "0.5.2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import konlpy\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "# print(plt.__version__)\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11890811",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821d78b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7cccd0308700>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7eedd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2ac0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 150000\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0d3510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95877dc6",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d8ee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document 열과 label 열의 중복을 제외한 값의 개수\n",
    "train_data['document'].nunique(), train_data['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7d54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document 열의 중복 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23be0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  73342\n",
      "1      1  72841\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d060d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207bf281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you expect people to read the FAQ etc and actually accept hard atheism\n"
     ]
    }
   ],
   "source": [
    "#알파벳과 공백을 제외하고 모두 제거\n",
    "eng_text = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\n",
    "print(re.sub(r'[^a-zA-Z ]', '', eng_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6b14ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24af12d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\", regex=True) # white space 데이터를 empty value로 변경\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7507b419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id document  label\n",
       "404   4221289      NaN      0\n",
       "412   9509970      NaN      1\n",
       "470  10147571      NaN      1\n",
       "584   7117896      NaN      0\n",
       "593   6478189      NaN      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.document.isnull()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9675d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145393\n",
      "After dropnaing a train_data\n",
      " id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                         아 더빙 진짜 짜증나네요 목소리\n",
       "1                                흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                                 교도소 이야기구먼 솔직히 재미는 없다평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...\n",
       "                                ...                        \n",
       "149995                                      인간이 문제지 소는 뭔죄인가\n",
       "149996                                           평점이 너무 낮아서\n",
       "149997                        이게 뭐요 한국인은 거들먹거리고 필리핀 혼혈은 착하다\n",
       "149998                           청춘 영화의 최고봉방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 145393, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any')\n",
    "print(len(train_data))\n",
    "print('After dropnaing a train_data\\n',train_data.isnull().sum())\n",
    "\n",
    "nsm_sentence = train_data['document']\n",
    "nsm_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5589df7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수 : 48852\n"
     ]
    }
   ],
   "source": [
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True) # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\", regex=True) # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aab8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length :  1\n",
      "Max length :  140\n",
      "Average length :  33\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARXklEQVR4nO3dbaxlVX3H8e+voFg1FZAppTOT3mmd1KCpQiYIsS8MVB6N2ETNGFOnlmTe0BQbEwVNSnwggbQRNVFaIhQ0BqRoywRtyRQwTV8IDkWRB6eMgmUm4IzyYK3ROvrvi7Mung73cu+dOXMe7vp+kpt79tr7nPM/a+b8zj5rr71vqgpJUh9+bdIFSJLGx9CXpI4Y+pLUEUNfkjpi6EtSR46cdAHP57jjjqu5ublJlyFJM+Wee+75QVWtWWjdVIf+3NwcO3bsmHQZkjRTknxvsXUO70hSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcM/RGYu/jLzF385UmXIUlLMvRHyPCXNO0MfUnqiKEvSR0x9CWpI1N9aeVp9nxj9/PrHr38vHGVI0nL4p6+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6siyQz/JEUnuTXJrW96Q5K4ku5J8IckLW/tRbXlXWz839BiXtPadSc4a+auRJD2vlezpXwQ8NLR8BXBlVb0CeAq4oLVfADzV2q9s25HkRGAz8CrgbODTSY44tPIlSSuxrNBPsg44D/hMWw5wOnBz2+R64C3t9vltmbb+jLb9+cCNVfWzqnoE2AWcMoLXIElapuXu6X8ceB/wy7b8cuDpqtrflncDa9vttcBjAG39M237Z9sXuM+zkmxNsiPJjn379i3/lUwhr7opadosGfpJ3gTsrap7xlAPVXV1VW2qqk1r1qwZx1NKUjeWc+2d1wNvTnIu8CLgN4BPAEcnObLtza8D9rTt9wDrgd1JjgReBvxwqH3e8H0kSWOw5J5+VV1SVeuqao7Bgdg7quqdwJ3AW9tmW4Bb2u1tbZm2/o6qqta+uc3u2QBsBO4e2SuZYvPDPA71SJq0Q7nK5vuBG5N8FLgXuKa1XwN8Lsku4EkGHxRU1QNJbgIeBPYDF1bVLw7h+SVJK7Si0K+qrwJfbbe/ywKzb6rqp8DbFrn/ZcBlKy1ymri3LmmWeUauJHXE0Jekjhj6ktQRQ1+SOmLoj5lTNyVNkqEvSR0x9CWpI4a+JHXE0Jekjhj6E+IBXUmTYOhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6E+bUTUnjZOhLUkcMfUnqiKEvSR1Z0R9G75nj7pJWA/f0Jakjhv6UcBaPpHEw9CWpI4a+JHXE0Jekjhj6U8axfUmHk6EvSR1xnv6UGt7bf/Ty8yZYiaTVxD19SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDf4Z44pakQ+U8/Rlg0EsaFff0Jakjhr4kdWTJ0E/yoiR3J/lmkgeSfKi1b0hyV5JdSb6Q5IWt/ai2vKutnxt6rEta+84kZx22VyVJWtBy9vR/BpxeVa8BXgucneRU4Argyqp6BfAUcEHb/gLgqdZ+ZduOJCcCm4FXAWcDn05yxAhfiyRpCUuGfg38uC2+oP0UcDpwc2u/HnhLu31+W6atPyNJWvuNVfWzqnoE2AWcMooX0Rtn8Ug6WMsa009yRJJvAHuB7cB3gKeran/bZDewtt1eCzwG0NY/A7x8uH2B+ww/19YkO5Ls2Ldv34pfkCRpccsK/ar6RVW9FljHYO/8lYeroKq6uqo2VdWmNWvWHK6nkaQurWj2TlU9DdwJnAYcnWR+nv86YE+7vQdYD9DWvwz44XD7AvfRIXC4R9JyLWf2zpokR7fbvw68EXiIQfi/tW22Bbil3d7Wlmnr76iqau2b2+yeDcBG4O4RvY4uGfaSVmo5Z+SeAFzfZtr8GnBTVd2a5EHgxiQfBe4FrmnbXwN8Lsku4EkGM3aoqgeS3AQ8COwHLqyqX4z25YyeoSppNVky9KvqPuCkBdq/ywKzb6rqp8DbFnmsy4DLVl6mJGkUPCNXkjpi6EtSRwx9SeqIoS9JHfF6+qvIQjONHr38vAlUImlauacvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHnKe/CK+uKWk1ck9fkjpi6EtSRwx9SeqIoS9JHTH0Vzn/jq6kYYZ+Jwx/SWDoS1JXDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUO/M87Xl/pm6EtSRwx9SeqIoS9JHfEvZx3A8W5Jq5l7+pLUEUNfkjri8E6nFhrGevTy8yZQiaRxck9fkjpi6OtZnrglrX6GviR1xNCXpI4Y+pLUkSVDP8n6JHcmeTDJA0kuau3HJtme5OH2+5jWniSfTLIryX1JTh56rC1t+4eTbDl8L0uStJDl7OnvB95bVScCpwIXJjkRuBi4vao2Are3ZYBzgI3tZytwFQw+JIBLgdcBpwCXzn9QaLp4QFdavZacp19VjwOPt9v/neQhYC1wPvCGttn1wFeB97f2z1ZVAV9LcnSSE9q226vqSYAk24GzgRtG+HoOigEnqRcrGtNPMgecBNwFHN8+EACeAI5vt9cCjw3dbXdrW6z9wOfYmmRHkh379u1bSXmSpCUs+4zcJC8Fvgi8p6p+lOTZdVVVSWoUBVXV1cDVAJs2bRrJY2o0PItXmn3L2tNP8gIGgf/5qvpSa/5+G7ah/d7b2vcA64fuvq61LdauKeXYvrT6LGf2ToBrgIeq6mNDq7YB8zNwtgC3DLW/q83iORV4pg0D3QacmeSYdgD3zNamKWf4S6vHcoZ3Xg/8CfCtJN9obR8ALgduSnIB8D3g7W3dV4BzgV3AT4B3A1TVk0k+Any9bffh+YO6kqTxWM7snX8HssjqMxbYvoALF3msa4FrV1KgJGl0PCNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4OiXP4pdli6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeW/TdyVyPPJB2d+b70b+ZK063L0DfsJfXK4R1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPoaqbmLv+xVTKUpZuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJk6Ce5NsneJPcPtR2bZHuSh9vvY1p7knwyya4k9yU5eeg+W9r2DyfZcnhejiTp+SxnT/864OwD2i4Gbq+qjcDtbRngHGBj+9kKXAWDDwngUuB1wCnApfMfFOPk2aKSerdk6FfVvwFPHtB8PnB9u3098Jah9s/WwNeAo5OcAJwFbK+qJ6vqKWA7z/0gkSQdZgc7pn98VT3ebj8BHN9urwUeG9pud2tbrP05kmxNsiPJjn379h1keZKkhRzygdyqKqBGUMv8411dVZuqatOaNWtG9bCSJA4+9L/fhm1ov/e29j3A+qHt1rW2xdolSWN0sKG/DZifgbMFuGWo/V1tFs+pwDNtGOg24Mwkx7QDuGe2Nq1SHjSXptORS22Q5AbgDcBxSXYzmIVzOXBTkguA7wFvb5t/BTgX2AX8BHg3QFU9meQjwNfbdh+uqgMPDkuSDrMlQ7+q3rHIqjMW2LaACxd5nGuBa1dUnSRppDwjV5I6YuhLUkcMfUnqiKEvSR0x9CWpI0vO3lkNnC8uSQNdhL4mZ/gD99HLz5tgJZLA4R2NkWfpSpNn6GvsDH9pcgx9SeqIoS9JHTH0NXEO90jjY+hLUkecsqmJce9eGj9DX1PHuf3S4WPoa2ostOc/32b4S6PhmL5migd9pUNj6EtSRxze0Uxw714aDUNfM+nADwHH/KXlcXhHq47j/tLi3NPXqvB8M3/m+W1AMvTVkeXs/fvBoNXO4R1pAQ4RabVyT19aBs8S1mph6EvPw719rTaGvjRkJSG/2CUivHSEppmhL63QYh8MB7YvtJ0fBJo0Q186RIfy7eD5vhX4jWG6LPXNbtg0/5ut6tB3PFbTajnfCjR5h/rvMo0f3Ks69KXVYLGTzJxRdOgW++a1nPsc6jaTYuhLM2YlZx+vZE9zGvdKx2WaQ3rUDH1pFVrJ8NGszz5abr2T/GY0TX1q6EudW2ovdzkHKg/3JS4OJTSX882oJ6mqSdewqE2bNtWOHTsO+v49/8NK02454+grGWufJYd7jz/JPVW1aaF17ulLmohZPyA6q7zgmiSN2SQv6GfoS1JHHN6RpAmZxIyise/pJzk7yc4ku5JcPO7nl6SejTX0kxwBfAo4BzgReEeSE8dZgyRNo3GN8497T/8UYFdVfbeq/he4ETh/zDVI0tQ63OE/7jH9tcBjQ8u7gdcNb5BkK7C1Lf44yc5DfM7jgB8c4mOMyyzVCrNV7yzVCrNV7yzVCjNSb64ADr7W31lsxdQdyK2qq4GrR/V4SXYsdpLCtJmlWmG26p2lWmG26p2lWmG26j0ctY57eGcPsH5oeV1rkySNwbhD/+vAxiQbkrwQ2AxsG3MNktStsQ7vVNX+JH8O3AYcAVxbVQ8c5qcd2VDRGMxSrTBb9c5SrTBb9c5SrTBb9Y681qm+4JokabS8DIMkdcTQl6SOrNrQn/bLPSRZn+TOJA8meSDJRa392CTbkzzcfh8z6VrnJTkiyb1Jbm3LG5Lc1fr4C+3g/FRIcnSSm5N8O8lDSU6b1r5N8pft/8D9SW5I8qJp6tsk1ybZm+T+obYF+zIDn2x135fk5Cmo9a/b/4P7kvxjkqOH1l3Sat2Z5Kxx1rpYvUPr3pukkhzXlkfSt6sy9Gfkcg/7gfdW1YnAqcCFrcaLgduraiNwe1ueFhcBDw0tXwFcWVWvAJ4CLphIVQv7BPAvVfVK4DUM6p66vk2yFvgLYFNVvZrBBIfNTFffXgecfUDbYn15DrCx/WwFrhpTjfOu47m1bgdeXVV/APwncAlAe79tBl7V7vPplh3jdB3PrZck64Ezgf8aah5N31bVqvsBTgNuG1q+BLhk0nUtUfMtwBuBncAJre0EYOeka2u1rGPw5j4duBUIgzMFj1yozydc68uAR2gTFYbap65v+dVZ6scymE13K3DWtPUtMAfcv1RfAn8HvGOh7SZV6wHr/hj4fLv9/3KBwazC0ybdt63tZgY7K48Cx42yb1flnj4LX+5h7YRqWVKSOeAk4C7g+Kp6vK16Ajh+UnUd4OPA+4BftuWXA09X1f62PE19vAHYB/x9G476TJKXMIV9W1V7gL9hsEf3OPAMcA/T27fzFuvLaX/v/Rnwz+32VNaa5HxgT1V984BVI6l3tYb+zEjyUuCLwHuq6kfD62rwcT7xObVJ3gTsrap7Jl3LMh0JnAxcVVUnAf/DAUM5U9S3xzC46OAG4LeBl7DA1/1pNi19uZQkH2QwrPr5SdeymCQvBj4A/NXheo7VGvozcbmHJC9gEPifr6ovtebvJzmhrT8B2Dup+oa8HnhzkkcZXBn1dAZj5kcnmT/Bb5r6eDewu6ruass3M/gQmMa+/SPgkaraV1U/B77EoL+ntW/nLdaXU/neS/KnwJuAd7YPKZjOWn+PwQ7AN9v7bR3wH0l+ixHVu1pDf+ov95AkwDXAQ1X1saFV24At7fYWBmP9E1VVl1TVuqqaY9CXd1TVO4E7gbe2zaaiVoCqegJ4LMnvt6YzgAeZwr5lMKxzapIXt/8T87VOZd8OWawvtwHvajNNTgWeGRoGmogkZzMYmnxzVf1kaNU2YHOSo5JsYHCA9O5J1Divqr5VVb9ZVXPt/bYbOLn9nx5N3477oMUYD46cy+BI/XeAD066ngXq+0MGX4nvA77Rfs5lMFZ+O/Aw8K/AsZOu9YC63wDc2m7/LoM3yS7gH4CjJl3fUJ2vBXa0/v0n4Jhp7VvgQ8C3gfuBzwFHTVPfAjcwON7w8xZCFyzWlwwO8H+qve++xWBW0qRr3cVgLHz+ffa3Q9t/sNW6EzhnGvr2gPWP8qsDuSPpWy/DIEkdWa3DO5KkBRj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSP/ByX6VhG1nDTjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for s in nsm_sentence:\n",
    "  if len(s) < min_len :\n",
    "    min_len = len(s)\n",
    "  if len(s) > max_len :\n",
    "    max_len = len(s)\n",
    "  sum_len += len(s)\n",
    "\n",
    "print('Min length : ', min_len)\n",
    "print('Max length : ', max_len)\n",
    "print('Average length : ', sum_len // len(nsm_sentence))\n",
    "\n",
    "sen_length_cnt = [0] * max_len\n",
    "for sen in nsm_sentence:\n",
    "  sen_length_cnt[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sen_length_cnt, width=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42a533e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130390\n",
      "130390\n"
     ]
    }
   ],
   "source": [
    "max_len = 140\n",
    "min_len = 10\n",
    "\n",
    "nsm_filtered_sen = []\n",
    "nsm_filtered_target = []\n",
    "\n",
    "target = np.array(train_data['label'])\n",
    "\n",
    "for s, t in zip(nsm_sentence, target):\n",
    "  if (len(str(s)) < max_len) and (len(str(s)) >= min_len) :\n",
    "    nsm_filtered_sen.append(s)\n",
    "    nsm_filtered_target.append(t)\n",
    "    \n",
    "print(len(nsm_filtered_sen))\n",
    "print(len(nsm_filtered_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b226672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus, vocab_path=\"./korean_spm.vocab\", padding='post'): \n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=padding)\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2cd21f",
   "metadata": {},
   "source": [
    "## Sentence Piece Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba8cbb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/nsm_train_bpe.txt.temp --model_prefix=korean_spm_nsm_bpe --model_type=bpe --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/nsm_train_bpe.txt.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm_nsm_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/nsm_train_bpe.txt.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 145393 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4944911\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1550\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 145393 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 145393\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 299292\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=58855 min_freq=78\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10818 size=20 all=117484 active=11835 piece=▁사\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8492 size=40 all=122473 active=16824 piece=▁점\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5826 size=60 all=126531 active=20882 piece=▁개\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5014 size=80 all=131360 active=25711 piece=▁왜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4050 size=100 all=135464 active=29815 piece=▁것\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4031 min_freq=64\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3558 size=120 all=138513 active=9769 piece=▁조\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3081 size=140 all=141682 active=12938 piece=리고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2775 size=160 all=144009 active=15265 piece=액션\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2538 size=180 all=146904 active=18160 piece=들의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2344 size=200 all=149744 active=21000 piece=▁최고의\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2337 min_freq=57\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2136 size=220 all=152667 active=10376 piece=▁지금\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1987 size=240 all=156005 active=13714 piece=▁모르\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1867 size=260 all=159256 active=16965 piece=▁아깝\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1761 size=280 all=161836 active=19545 piece=▁우리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1623 size=300 all=164283 active=21992 piece=▁잔\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1622 min_freq=51\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1492 size=320 all=166209 active=10101 piece=재미\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1426 size=340 all=168395 active=12287 piece=▁줄\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1357 size=360 all=171211 active=15103 piece=▁힘\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1268 size=380 all=173490 active=17382 piece=니까\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1227 size=400 all=175804 active=19696 piece=인지\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1227 min_freq=46\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1178 size=420 all=178324 active=10965 piece=▁계\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1113 size=440 all=180503 active=13144 piece=스러\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1076 size=460 all=182322 active=14963 piece=▁돌\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1010 size=480 all=184590 active=17231 piece=▁프\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=968 size=500 all=186393 active=19034 piece=된다\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=960 min_freq=43\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=924 size=520 all=188461 active=11240 piece=리가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=896 size=540 all=190696 active=13475 piece=을때\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=873 size=560 all=193117 active=15896 piece=생각\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=847 size=580 all=195513 active=18292 piece=▁흥미\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=822 size=600 all=198062 active=20841 piece=▁즐\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=818 min_freq=39\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=788 size=620 all=200378 active=12202 piece=▁않은\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=771 size=640 all=202644 active=14468 piece=성이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=748 size=660 all=205044 active=16868 piece=해요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=721 size=680 all=207073 active=18897 piece=▁홍\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=698 size=700 all=208549 active=20373 piece=기가\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=697 min_freq=36\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=671 size=720 all=210342 active=12023 piece=▁왜이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=659 size=740 all=211691 active=13372 piece=▁너무나\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=643 size=760 all=213165 active=14846 piece=▁의미\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=627 size=780 all=214727 active=16408 piece=더니\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=615 size=800 all=216309 active=17990 piece=었습니다\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=614 min_freq=35\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=603 size=820 all=217891 active=12287 piece=▁무서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=581 size=840 all=219378 active=13774 piece=▁좋았다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=566 size=860 all=220577 active=14973 piece=▁우리나라\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=556 size=880 all=222031 active=16427 piece=▁시나리오\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=545 size=900 all=223287 active=17683 piece=아깝\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=544 min_freq=33\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=534 size=920 all=224646 active=12430 piece=▁환\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=523 size=940 all=225972 active=13756 piece=▁큰\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=514 size=960 all=226909 active=14693 piece=을듯\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=500 size=980 all=228454 active"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 376816 Feb 25 03:09 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 533947 Feb 25 03:13 korean_spm_naver_sentiment_movie.model\r\n",
      "-rw-r--r-- 1 root root 310400 Feb 25 03:13 korean_spm_naver_sentiment_movie.vocab\r\n",
      "-rw-r--r-- 1 root root 373419 Feb 25 07:40 korean_spm_nsm_bpe.model\r\n",
      "-rw-r--r-- 1 root root 118628 Feb 25 07:40 korean_spm_nsm_bpe.vocab\r\n",
      "-rw-r--r-- 1 root root 377804 Feb 25 06:14 korean_spm_nsm.model\r\n",
      "-rw-r--r-- 1 root root 147291 Feb 25 06:14 korean_spm_nsm.vocab\r\n",
      "-rw-r--r-- 1 root root 146213 Feb 25 03:09 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "nsm_temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/nsm_train_bpe.txt.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(nsm_temp_file, 'w') as f:\n",
    "    for row in nsm_sentence:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_nsm_bpe --model_type=bpe --vocab_size={}'.format(nsm_temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cae26b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsm_spm = spm.SentencePieceProcessor()\n",
    "nsm_spm.Load('./korean_spm_nsm_bpe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "981c33ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130390, 111)\n",
      "[[   0    0    0 ... 2293   35 2010]\n",
      " [   0    0    0 ... 6455   63  393]\n",
      " [   0    0    0 ... 1170 1757  275]\n",
      " ...\n",
      " [   0    0    0 ... 6471 1428   77]\n",
      " [   0    0    0 ...   80 6456 6522]\n",
      " [   0    0    0 ...  616 5516    4]]\n",
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "nsm_tensor, nsm_word_index, nsme_index_word = sp_tokenize(nsm_spm, nsm_filtered_sen, \"./korean_spm_nsm_bpe.vocab\", padding='pre')\n",
    "print(nsm_tensor.shape)\n",
    "print(nsm_tensor)\n",
    "print(len(nsm_word_index))\n",
    "print(len(nsme_index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dc2adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, val_x, y_train, val_y = train_test_split(nsm_tensor, nsm_filtered_target, test_size=0.2)\n",
    "y_train = np.array(y_train)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "497a3d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104312, 111)\n",
      "(104312,)\n",
      "(26078,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1ea3c",
   "metadata": {},
   "source": [
    "## LSTM으로 네이버 영화 리뷰 감성 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a5bc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1304/1304 [==============================] - 13s 9ms/step - loss: 0.4093 - acc: 0.8115 - val_loss: 0.3727 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83794, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1304/1304 [==============================] - 11s 8ms/step - loss: 0.3242 - acc: 0.8596 - val_loss: 0.3377 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83794 to 0.85424, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1304/1304 [==============================] - 11s 8ms/step - loss: 0.2980 - acc: 0.8719 - val_loss: 0.3306 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85424 to 0.85611, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "1304/1304 [==============================] - 11s 8ms/step - loss: 0.2782 - acc: 0.8827 - val_loss: 0.3373 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85611\n",
      "Epoch 5/15\n",
      "1304/1304 [==============================] - 11s 8ms/step - loss: 0.2597 - acc: 0.8915 - val_loss: 0.3368 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.85611\n",
      "Epoch 6/15\n",
      "1304/1304 [==============================] - 11s 8ms/step - loss: 0.2467 - acc: 0.8991 - val_loss: 0.3408 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.85611\n",
      "Epoch 7/15\n",
      "1304/1304 [==============================] - 10s 8ms/step - loss: 0.2316 - acc: 0.9066 - val_loss: 0.3476 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85611\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "916ca4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/815 [==============================] - 3s 3ms/step - loss: 0.3308 - acc: 0.8568\n",
      "\n",
      " 테스트 정확도: 0.8568\n"
     ]
    }
   ],
   "source": [
    "load_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (load_model.evaluate(val_x, val_y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475402b",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "팀에서 데이터 전처리와 RNN 모델을 정의 한 후 vocab_size, padding, model_type에 변경에 따른 정확성 정도를 측정 하기로 진행 하였습니다.\n",
    "\n",
    "제 케이스는 vocab_size=8000, padding=post,pre, model_type(spm)=unigram, bpe 였습니다.\n",
    "\n",
    "8000\tpost-padding\tunigram\t\t0.5046\n",
    "\t\tpost-padding\tbpe\t\t    0.5035\n",
    "\t\tpre-padding\t    unigram\t\t0.8577\n",
    "\t\tpre-padding\t    bpe\t\t    0.8578\n",
    "        \n",
    "제 케이스의 결과는 sentencepiece의 모델 타입에 따른 차이는 없었고, 토근의 패딩 방식에 따라 차이가 많이 났습니다.\n",
    "한글 이라 pre padding이 조금 좋은 결과가 나올 거라 예상 했는데, 너무 차이가 많이 났어 어떻게 해석해야 할지 모르겠습니다.\n",
    "\n",
    "        \n",
    "데이터 전처리와 RNN 모델이 동일한 조건에서,\n",
    "konlpy의 Okt로 진행 했을때 정확도가 0.8544 였어, 위 pre padding과 차이가 크지 않았습니다.\n",
    "\n",
    "lecture에서 언급 된 데로 subword 방식으로 토큰화 하여도 언어에 따른 차이가 크지 않다는 것을 확인 할 수 있었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
